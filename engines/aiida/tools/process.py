"""
Unified Process Tool for AiiDA.
Handles WorkChains, Calculations, and Provenance Trees.
"""
from collections import defaultdict
from typing import Union, Dict, Any
import json
from aiida import orm
from aiida.orm import Log, QueryBuilder, ProcessNode, WorkflowNode, CalcJobNode
from engines.aiida.tools.process_tree import ProcessTree

# --- AI æ ¸å¿ƒæ¥å£ (The Hub) ---

def inspect_process(identifier: str) -> str: # ğŸš© å°† Union[str, int] æ”¹ä¸º str
    """
    Inspect an AiiDA process (WorkChain or Calculation).
    Args:
        identifier (str): The PK (as string) or UUID of the process.
    """
    try:
        # load_node èƒ½å¤Ÿè‡ªåŠ¨å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„æ•°å­— PK
        node = orm.load_node(identifier)

        if not isinstance(node, ProcessNode):
            return f"Error: Node {identifier} is a {type(node)}, not a ProcessNode."

        # 1. æ„å»ºè°ƒç”¨æ ‘
        tree = ProcessTree(node)
        
        # 2. è·å–é’ˆå¯¹æ€§æ—¥å¿—
        logs = get_process_log(node.pk)
        
        # 3. ç»„è£…ç»¼åˆæŠ¥å‘Š
        report = {
            "summary": {
                "pk": node.pk,
                "uuid": node.uuid,
                "type": node.node_type.split('.')[-2],
                "label": node.label,
                "state": node.process_state.value if hasattr(node, 'process_state') else "N/A",
                "exit_status": getattr(node, "exit_status", None),
                "exit_message": getattr(node, "exit_message", None),
            },
            "provenance_tree": tree.to_dict(),
            "logs": logs,
            "attributes": node.base.attributes.all,
        }
        
        # é’ˆå¯¹ CalcJob çš„ç‰¹åŒ–ä¿¡æ¯
        if isinstance(node, CalcJobNode):
            report["summary"]["is_calcjob"] = True
            report["files"] = node.list_objects()

        return json.dumps(report, indent=2, default=str)
    except Exception as e:
        return f"Error inspecting process '{identifier}': {str(e)}"

def get_process_log(pk: int) -> str:
    """
    è·å–è¿›ç¨‹çš„æ··åˆæ—¥å¿—ï¼š
    - å¦‚æœæ˜¯ WorkChainï¼šæŠ“å–å†…éƒ¨ report æ¶ˆæ¯
    - å¦‚æœæ˜¯ CalcJobï¼šæŠ“å–è°ƒåº¦å™¨ stderr
    """
    try:
        node = orm.load_node(pk)
        log_lines = []

        # 1. å°è¯•æŠ“å– WorkChain çš„ Report (æ¥è‡ª Log è¡¨)
        qb = QueryBuilder().append(Log, filters={'objpk': pk}, project=['message', 'time'])
        if qb.count() > 0:
            log_lines.append("--- WorkChain Reports ---")
            for msg, time in qb.order_by({Log: {'time': 'asc'}}).all():
                log_lines.append(f"[{time.strftime('%H:%M:%S')}] {msg}")

        # 2. å°è¯•æŠ“å– CalcJob çš„è°ƒåº¦å™¨é”™è¯¯
        if isinstance(node, CalcJobNode) and 'retrieved' in node.outputs:
            stderr = node.get_scheduler_stderr()
            if stderr:
                log_lines.append("--- Scheduler Stderr ---")
                log_lines.append(stderr[-2000:]) # ä»…æˆªå–æœ€å2000å­—ï¼Œé˜²æ­¢ Token çˆ†ç‚¸

        return "\n".join(log_lines) if log_lines else "No detailed logs found."
    except Exception as e:
        return f"Could not retrieve logs: {e}"

def fetch_recent_processes(limit: int = 15):
    """è·å–æœ€è¿‘ä»»åŠ¡åˆ—è¡¨ï¼Œå¸¸ç”¨äºæ„ŸçŸ¥å™¨æä¾›å…¨å±€ä¸Šä¸‹æ–‡ã€‚"""
    qb = QueryBuilder().append(
        ProcessNode, 
        project=["id", "attributes.process_label", "attributes.process_state", "ctime"],
        limit=limit
    ).order_by({ProcessNode: {"ctime": "desc"}})
    
    results = []
    for pk, label, state, ctime in qb.all():
        results.append({
            "PK": pk, "Label": label, "State": state, 
            "Created": ctime.strftime("%m-%d %H:%M")
        })
    return results